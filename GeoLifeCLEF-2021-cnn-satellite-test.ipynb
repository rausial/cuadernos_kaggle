{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa857863",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment=None\n",
    "\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36d88e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this path to adapt to where you downloaded the data\n",
    "BASE_PATH = Path(\"/storage/geolifeclef-2021/\")\n",
    "DATA_PATH = BASE_PATH / \"data\"\n",
    "\n",
    "# Create the path to save submission files\n",
    "SUBMISSION_PATH = Path(\"submissions\")\n",
    "os.makedirs(SUBMISSION_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91287d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data sources: 4\n",
      "Arrays shape: [(256, 256, 3), (256, 256), (256, 256), (256, 256)]\n",
      "Data types: [dtype('uint8'), dtype('uint8'), dtype('int16'), dtype('uint8')]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append( '../' )\n",
    "from GLC.data_loading.common import load_patch\n",
    "from GLC.plotting import visualize_observation_patch\n",
    "from GLC.metrics import top_30_error_rate\n",
    "from GLC.metrics import top_k_error_rate_from_sets\n",
    "from GLC.metrics import predict_top_30_set, predict_top_k_set\n",
    "\n",
    "PATCHES_PATH = DATA_PATH / \"patches/\"\n",
    "patch = load_patch(10000000, PATCHES_PATH)\n",
    "\n",
    "print(\"Number of data sources: {}\".format(len(patch)))\n",
    "print(\"Arrays shape: {}\".format([p.shape for p in patch]))\n",
    "print(\"Data types: {}\".format([p.dtype for p in patch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0353323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x(r):\n",
    "    \"\"\"Loads the patch data associated to an observation id\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    observation_id : integer\n",
    "        Identifier of the observation.\n",
    "    patches_path : string / pathlib.Path\n",
    "        Path to the folder containing all the patches.\n",
    "    landcover_mapping : 1d array-like\n",
    "        Facultative mapping of landcover codes, useful to align France and US codes.\n",
    "    return_arrays : boolean\n",
    "        If True, returns all the patches as Numpy arrays (no PIL.Image returned).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    patches : tuple of size 4 containing 2d array-like objects\n",
    "        Returns a tuple containing all the patches in the following order: RGB, Near-IR, altitude and landcover.\n",
    "    \"\"\"\n",
    "    observation_id = str(r['observation_id'])\n",
    "\n",
    "    region_id = observation_id[0]\n",
    "    if region_id == \"1\":\n",
    "        region = \"fr\"\n",
    "    elif region_id == \"2\":\n",
    "        region = \"us\"\n",
    "    else:\n",
    "        raise ValueError(\"Incorrect 'observation_id' {}, can not extract region id from it\".format(observation_id))\n",
    "\n",
    "    subfolder1 = observation_id[-2:]\n",
    "    subfolder2 = observation_id[-4:-2]\n",
    "\n",
    "    filename = Path(PATCHES_PATH) / region / subfolder1 / subfolder2 / observation_id\n",
    "\n",
    "    rgb_filename = filename.with_name(filename.stem + \"_rgb.jpg\")\n",
    "    \n",
    "    return rgb_filename\n",
    "\n",
    "def get_y(r):\n",
    "    species_id = r['species_id']\n",
    "    \n",
    "    return species_id\n",
    "\n",
    "def splitter(df):\n",
    "    train = df.index[df['subset'] == 'train'].tolist()\n",
    "    valid = df.index[df['subset'] != 'train'].tolist()\n",
    "    return train,valid\n",
    "\n",
    "def get_observations(data_path):\n",
    "    df_fr = pd.read_csv(data_path / \"observations\" / \"observations_fr_train.csv\",\n",
    "                        sep=\";\", index_col=\"observation_id\")\n",
    "    df_us = pd.read_csv(data_path / \"observations\" / \"observations_us_train.csv\",\n",
    "                        sep=\";\", index_col=\"observation_id\")\n",
    "    \n",
    "    df = pd.concat((df_fr, df_us))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d3ac999",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = load_pickle('dataloaders.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df0d9458",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = load_pickle('observations_test_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65e8ae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dd6fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load(file='geolife-21-cnn_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b7462a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = df_val.species_id.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b8bd681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dl_t = learn.dls.test_dl(df_val, bs=128)\n",
    "preds, _ = learn.get_preds(dl=dl_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0301be01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-30 error rate: 81.1%\n"
     ]
    }
   ],
   "source": [
    "preds_ids = array([learn.dls.vocab[pred] for pred in predict_top_k_set(preds, 30)])\n",
    "score_val = top_k_error_rate_from_sets(y_val, preds_ids)\n",
    "print(\"Top-30 error rate: {:.1%}\".format(score_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85dc39dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_observations(data_path):\n",
    "    df_fr_test = pd.read_csv(DATA_PATH / \"observations\" / \"observations_fr_test.csv\", sep=\";\",\n",
    "                             low_memory=False, dtype={'observation_id': str})\n",
    "    df_us_test = pd.read_csv(DATA_PATH / \"observations\" / \"observations_us_test.csv\", sep=\";\",\n",
    "                             low_memory=False, dtype={'observation_id': str})\n",
    "    \n",
    "    df_test = pd.concat((df_fr_test, df_us_test))\n",
    "    return df_test\n",
    "\n",
    "def generate_submission_file(filename, corrected_observation_ids, s_pred):\n",
    "    s_pred = [\n",
    "        \" \".join(map(str, pred_set))\n",
    "        for pred_set in s_pred\n",
    "    ]\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        \"Id\": corrected_observation_ids,\n",
    "        \"Predicted\": s_pred\n",
    "    })\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db34ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = get_test_observations(DATA_PATH)\n",
    "df_test_obs_id_mapping = pd.read_csv(BASE_PATH / \"test_observation_ids_mapping.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a066f9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dl_t = learn.dls.test_dl(df_test, bs=256)\n",
    "preds, _ = learn.get_preds(dl=dl_t)\n",
    "preds_ids = array([learn.dls.vocab[pred] for pred in predict_top_k_set(preds, 30)])\n",
    "\n",
    "# Generate the submission file\n",
    "generate_submission_file(SUBMISSION_PATH/\"fastai_cnn_rbg.csv\", df_test_obs_id_mapping[\"Id\"], preds_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f4cc143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 5.67M/5.67M [00:00<00:00, 10.8MB/s]\n",
      "Successfully submitted to GeoLifeCLEF 2021 - LifeCLEF 2021 x FGVC8"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c geolifeclef-2021 -f {SUBMISSION_PATH/\"fastai_cnn_rbg.csv\"} -m \"fastai cnn submission\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b7cbcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
